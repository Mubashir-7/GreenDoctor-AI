{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6cf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "', classification_report(y_true, y_pred, target_names=class_names))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(class_names)), class_names, rotation=90)\n",
    "    plt.yticks(np.arange(len(class_names)), class_names)\n",
    "    plt.show()\n",
    "\n",
    "# If we have history from training, plot it\n",
    "try:\n",
    "    plot_history(history)\n",
    "    evaluate_and_confusion(model, val_ds, CLASS_NAMES)\n",
    "except Exception as e:\n",
    "    print('Plot/evaluation skipped (no training run found in session):', e)\n",
    "\n",
    "# CODE\n",
    "# 10) Advanced: how to combine CNN bottleneck features with histogram features\n",
    "#  - Extract bottleneck features (from base model)\n",
    "#  - Concatenate with histogram vectors\n",
    "#  - Train a small dense head on top (multi-input)\n",
    "\n",
    "def extract_bottleneck_features(dataset, base_model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for images, labs in dataset:\n",
    "        x = tf.keras.applications.efficientnet.preprocess_input(images)\n",
    "        feats = base_model.predict(x)\n",
    "        features.append(feats)\n",
    "        labels.append(labs.numpy())\n",
    "    features = np.vstack(features)\n",
    "    labels = np.vstack(labels)\n",
    "    return features, labels\n",
    "\n",
    "# Example pipeline (do not run automatically - heavy)\n",
    "print('To combine features: 1) extract bottleneck features with base model (include_top=False, pooling=avg).')\n",
    "print('2) compute histograms for the same images, 3) concatenate arrays and train a dense classifier (e.g. sklearn or Keras).')\n",
    "\n",
    "# MD\n",
    "## Tips & next steps\n",
    "\n",
    "- **Use a GPU** for real training (set EPOCHS=20-50 depending on dataset size).\n",
    "- **Unfreeze top layers** of the base model and fine-tune with a smaller LR (e.g. 1e-5) after initial training.\n",
    "- **Class imbalance:** If very imbalanced, use `class_weight` (we added automatic compute) or oversample minority classes.\n",
    "- **Augmentation:** tweak augmentation strength (rotation, zoom) to match your problem.\n",
    "- **Monitoring:** use TensorBoard for detailed per-layer metrics.\n",
    "- **If accuracy is still poor:** try larger models (EfficientNetB3 / ResNet101), or a bigger input size (e.g., 380x380) if GPU allows.\n",
    "\n",
    "---\n",
    "\n",
    "**Files created (if you run training)**\n",
    "\n",
    "- `final_model.h5` - saved model after training.\n",
    "- `best_model.h5` - checkpoint saved during training.\n",
    "\n",
    "Good luck! Run the notebook end-to-end and paste the training logs or validation metrics here and I'll help you tune hyperparameters.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
